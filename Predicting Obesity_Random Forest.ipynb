{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d48b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing package\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "import warnings\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# importing data\n",
    "\n",
    "# data import -- google colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#file_path = '/content/drive/MyDrive/ObesityDataSet_raw_and_data_sinthetic.csv'\n",
    "#df = pd.read_csv(file_path)\n",
    "# data import -- jupyter notebook\n",
    "df = pd.read_csv(\"ObesityDataSet_raw_and_data_sinthetic.csv\")\n",
    "df = df.rename(columns={'family_history_with_overweight': 'FHWO', 'NObeyesdad' : 'Obesity Level',})\n",
    "cols = df.columns\n",
    "num_cols = df._get_numeric_data().columns\n",
    "cat_cols = list(set(cols) - set(num_cols))\n",
    "for i in cat_cols:\n",
    "    col_val = sorted(list(set(df[i].tolist())))\n",
    "    replace_num = []\n",
    "    for j in range(len(col_val)):\n",
    "        replace_num.append(j)\n",
    "    df[i].replace(col_val,replace_num, inplace=True)\n",
    "outlier_index = [18, 21, 25, 30, 68, 92, 119, 132, 133, 142, 152, 188, 191, 200, 217, 232, 236, 245, 252, 277, 333, 495]\n",
    "df_remove_outliers = df\n",
    "df_remove_outliers = df_remove_outliers.drop(outlier_index)\n",
    "df_remove_outliers = df_remove_outliers.reset_index(drop=True)\n",
    "\n",
    "columns = ['Height', 'Weight']\n",
    "df_remove_outliers.drop(columns, inplace=True, axis=1)\n",
    "df.drop(columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ba8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Age', 'Gender', 'FHWO', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS']\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df[features])\n",
    "\n",
    "target_name = 'Obesity Level'\n",
    "y = df[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d75889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model(before outliers removal):\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8392434988179669\n",
      "Classification Report of Random Forest Classifier : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8814    0.9286    0.9043        56\n",
      "           1     0.6716    0.7258    0.6977        62\n",
      "           2     0.8395    0.8718    0.8553        78\n",
      "           3     0.8333    0.9483    0.8871        58\n",
      "           4     1.0000    1.0000    1.0000        63\n",
      "           5     0.7959    0.6964    0.7429        56\n",
      "           6     0.8684    0.6600    0.7500        50\n",
      "\n",
      "    accuracy                         0.8392       423\n",
      "   macro avg     0.8415    0.8330    0.8339       423\n",
      "weighted avg     0.8411    0.8392    0.8373       423\n",
      "\n",
      "Confusion Matrix: \n",
      "[[52  2  0  0  0  2  0]\n",
      " [ 5 45  4  1  0  4  3]\n",
      " [ 0  5 68  3  0  1  1]\n",
      " [ 0  3  0 55  0  0  0]\n",
      " [ 0  0  0  0 63  0  0]\n",
      " [ 1  9  5  1  0 39  1]\n",
      " [ 1  3  4  6  0  3 33]]\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train_features, train_labels)\n",
    "\n",
    "train_score = rfc.score(train_features, train_labels)\n",
    "test_score = rfc.score(test_features, test_labels)\n",
    "\n",
    "rfc_pred = rfc.predict(test_features)\n",
    "\n",
    "cm = confusion_matrix(test_labels,rfc_pred)\n",
    "mcc = matthews_corrcoef(test_labels, rfc_pred)\n",
    "report_best = classification_report(test_labels, rfc_pred, digits=4)\n",
    "\n",
    "print('Random Forest Model(before outliers removal):')\n",
    "print('Train accuracy:', train_score)\n",
    "print('Test accuracy:', test_score)\n",
    "print('Classification Report of Random Forest Classifier : \\n', report_best)\n",
    "print('Confusion Matrix: ')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74818285",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Age', 'Gender', 'FHWO', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS']\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df_remove_outliers[features])\n",
    "\n",
    "target_name = 'Obesity Level'\n",
    "y = df_remove_outliers[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c338b5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model (after outliers removal):\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8516746411483254\n",
      "Classification Report of Random Forest Classifier : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9434    0.8333    0.8850        60\n",
      "           1     0.5970    0.7692    0.6723        52\n",
      "           2     0.8947    0.7969    0.8430        64\n",
      "           3     0.9077    0.9365    0.9219        63\n",
      "           4     1.0000    0.9865    0.9932        74\n",
      "           5     0.7885    0.7885    0.7885        52\n",
      "           6     0.8235    0.7925    0.8077        53\n",
      "\n",
      "    accuracy                         0.8517       418\n",
      "   macro avg     0.8507    0.8433    0.8445       418\n",
      "weighted avg     0.8630    0.8517    0.8550       418\n",
      "\n",
      "Confusion Matrix: \n",
      "[[50 10  0  0  0  0  0]\n",
      " [ 3 40  1  0  0  5  3]\n",
      " [ 0  6 51  2  0  3  2]\n",
      " [ 0  3  0 59  0  0  1]\n",
      " [ 0  0  0  0 73  0  1]\n",
      " [ 0  4  3  2  0 41  2]\n",
      " [ 0  4  2  2  0  3 42]]\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "rfc_best = RandomForestClassifier()\n",
    "rfc_best.fit(train_features, train_labels)\n",
    "\n",
    "train_score = rfc_best.score(train_features, train_labels)\n",
    "test_score = rfc_best.score(test_features, test_labels)\n",
    "\n",
    "rfc_pred = rfc_best.predict(test_features)\n",
    "\n",
    "cm = confusion_matrix(test_labels,rfc_pred)\n",
    "\n",
    "report_best = classification_report(test_labels, rfc_pred, digits=4)\n",
    "\n",
    "print('Random Forest Model (after outliers removal):')\n",
    "print('Train accuracy:', train_score)\n",
    "print('Test accuracy:', test_score)\n",
    "print('Classification Report of Random Forest Classifier : \\n', report_best)\n",
    "print('Confusion Matrix: ')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a266e0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model with Grid Search:\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8660287081339713\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9434    0.8333    0.8850        60\n",
      "           1     0.6269    0.8077    0.7059        52\n",
      "           2     0.9123    0.8125    0.8595        64\n",
      "           3     0.9365    0.9365    0.9365        63\n",
      "           4     1.0000    0.9865    0.9932        74\n",
      "           5     0.8077    0.8077    0.8077        52\n",
      "           6     0.8302    0.8302    0.8302        53\n",
      "\n",
      "    accuracy                         0.8660       418\n",
      "   macro avg     0.8653    0.8592    0.8597       418\n",
      "weighted avg     0.8770    0.8660    0.8692       418\n",
      "\n",
      "Confusion Matrix: \n",
      "[[50  9  0  0  0  1  0]\n",
      " [ 2 42  1  0  0  5  2]\n",
      " [ 0  6 52  2  0  2  2]\n",
      " [ 0  3  0 59  0  0  1]\n",
      " [ 0  0  0  0 73  0  1]\n",
      " [ 0  4  2  1  0 42  3]\n",
      " [ 1  3  2  1  0  2 44]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 1000],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth' : [10, 50],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'min_samples_leaf': [1, 4],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc_best, param_grid=param_grid, cv=5)\n",
    "CV_rfc.fit(train_features, train_labels)\n",
    "best_model = CV_rfc.best_estimator_\n",
    "\n",
    "train_preds = best_model.predict(train_features)\n",
    "train_acc = accuracy_score(train_labels, train_preds)\n",
    "\n",
    "test_preds = best_model.predict(test_features)\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "\n",
    "rfc_hyperGS = best_model.predict(test_features)\n",
    "cm_hyper = confusion_matrix(test_labels,rfc_hyperGS)\n",
    "\n",
    "report_hyperGS = classification_report(test_labels, rfc_hyperGS, digits=4)\n",
    "\n",
    "print('Random Forest Model with Grid Search:')\n",
    "print('Best hyperparameters:', CV_rfc.best_params_)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "print('Classification Report:')\n",
    "print(report_hyperGS)\n",
    "print('Confusion Matrix: ')\n",
    "print(cm_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b5209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Random Forest Model with Random Search:\n",
      "Best hyperparameters: {'n_estimators': 255, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 45, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8708133971291866\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9608    0.8167    0.8829        60\n",
      "           1     0.6087    0.8077    0.6942        52\n",
      "           2     0.9273    0.7969    0.8571        64\n",
      "           3     0.9524    0.9524    0.9524        63\n",
      "           4     1.0000    0.9865    0.9932        74\n",
      "           5     0.7818    0.8269    0.8037        52\n",
      "           6     0.8846    0.8679    0.8762        53\n",
      "\n",
      "    accuracy                         0.8708       418\n",
      "   macro avg     0.8737    0.8650    0.8657       418\n",
      "weighted avg     0.8856    0.8708    0.8748       418\n",
      "\n",
      "Confusion Matrix: \n",
      "[[49 10  0  0  0  1  0]\n",
      " [ 2 42  1  0  0  5  2]\n",
      " [ 0  6 51  2  0  3  2]\n",
      " [ 0  3  0 60  0  0  0]\n",
      " [ 0  1  0  0 73  0  0]\n",
      " [ 0  4  2  1  0 43  2]\n",
      " [ 0  3  1  0  0  3 46]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Random Search\n",
    "param_random = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(100, 300, num = 10)],\n",
    "    'max_features': ['sqrt', 'log2', 10, 12, 15],\n",
    "    'max_depth' : [int(x) for x in np.linspace(10, 50, num = 10)],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1,2,3],\n",
    "    'criterion' : ['gini','entropy'],\n",
    "    'bootstrap' : [True,False]\n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=rfc_best,\n",
    "                                   param_distributions=param_random,\n",
    "                                   n_iter = 50,\n",
    "                                   cv=10, \n",
    "                                   verbose=True, \n",
    "                                   n_jobs = -1)\n",
    "\n",
    "random_search.fit(train_features, train_labels)\n",
    "best_model = random_search.best_estimator_\n",
    "train_acc = best_model.score(train_features, train_labels)\n",
    "test_acc = best_model.score(test_features, test_labels)\n",
    "rfc_hyperRS = best_model.predict(test_features)\n",
    "cm_hyper = confusion_matrix(test_labels,rfc_hyperRS)\n",
    "\n",
    "report_hyperRS = classification_report(test_labels, rfc_hyperRS, digits=4)\n",
    "\n",
    "print('Random Forest Model with Random Search:')\n",
    "print('Best hyperparameters:', random_search.best_params_)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "print('Classification Report:')\n",
    "print(report_hyperRS)\n",
    "print('Confusion Matrix: ')\n",
    "print(cm_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2810c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model with Bayes Optimization:\n",
      "Best hyperparameters: OrderedDict([('criterion', 'entropy'), ('max_depth', 39), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 863)])\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8779904306220095\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9623    0.8500    0.9027        60\n",
      "           1     0.6515    0.8269    0.7288        52\n",
      "           2     0.9298    0.8281    0.8760        64\n",
      "           3     0.9375    0.9524    0.9449        63\n",
      "           4     1.0000    0.9865    0.9932        74\n",
      "           5     0.8039    0.7885    0.7961        52\n",
      "           6     0.8519    0.8679    0.8598        53\n",
      "\n",
      "    accuracy                         0.8780       418\n",
      "   macro avg     0.8767    0.8715    0.8716       418\n",
      "weighted avg     0.8879    0.8780    0.8807       418\n",
      "\n",
      "Confusion Matrix: \n",
      "[[49 10  0  0  0  1  0]\n",
      " [ 2 42  1  0  0  5  2]\n",
      " [ 0  6 51  2  0  3  2]\n",
      " [ 0  3  0 60  0  0  0]\n",
      " [ 0  1  0  0 73  0  0]\n",
      " [ 0  4  2  1  0 43  2]\n",
      " [ 0  3  1  0  0  3 46]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Bayes Optimization\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"skopt.optimizer.optimizer\")\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 1000],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth' : [10, 50],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'min_samples_leaf': [1, 4],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    estimator = rfc_best,\n",
    "    search_spaces=param_grid,\n",
    "    n_iter=100,  # Number of evaluations\n",
    "    cv=5,  # Cross-validation folds\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "opt.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "best_rfc_model = opt.best_estimator_\n",
    "train_acc = best_rfc_model.score(train_features, train_labels)\n",
    "test_preds = best_rfc_model.predict(test_features)\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "report_hyperBO = classification_report(test_labels, test_preds, digits=4)\n",
    "\n",
    "rfc_hyperBO = best_model.predict(test_features)\n",
    "cm_hyper = confusion_matrix(test_labels,rfc_hyperBO)\n",
    "\n",
    "print('Random Forest Model with Bayes Optimization:')\n",
    "print('Best hyperparameters:', opt.best_params_)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "print('Classification Report:')\n",
    "print(report_hyperBO)\n",
    "print('Confusion Matrix: ')\n",
    "print(cm_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beaa4af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> accuracy = 0.837321, Best_params = {'criterion': 'gini', 'max_depth': 50, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "> accuracy = 0.775120, Best_params = {'criterion': 'gini', 'max_depth': 50, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "> accuracy = 0.822967, Best_params = {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "> accuracy = 0.813397, Best_params = {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "> accuracy = 0.779904, Best_params = {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "> accuracy = 0.784689, Best_params = {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "> accuracy = 0.832536, Best_params = {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "> accuracy = 0.794258, Best_params = {'criterion': 'gini', 'max_depth': 50, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "> accuracy = 0.861244, Best_params = {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "> accuracy = 0.812500, Best_params = {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Fold 1 - Selected Features: ['Age', 'Gender', 'CH2O', 'FAF']\n",
      "Fold 2 - Selected Features: ['Age', 'Gender', 'CH2O', 'FAF']\n",
      "Fold 3 - Selected Features: ['Age', 'Gender', 'CH2O', 'FAF']\n",
      "Fold 4 - Selected Features: ['Age', 'Gender', 'CH2O', 'FAF']\n",
      "Fold 5 - Selected Features: ['Age', 'Gender', 'CH2O', 'FAF']\n",
      "Fold 6 - Selected Features: ['Age', 'Gender', 'CH2O', 'FAF']\n",
      "Fold 7 - Selected Features: ['Age', 'Gender', 'CH2O', 'FAF']\n",
      "Fold 8 - Selected Features: ['Age', 'Gender', 'CH2O', 'FAF']\n",
      "Fold 9 - Selected Features: ['Age', 'Gender', 'CH2O', 'FAF']\n",
      "Fold 10 - Selected Features: ['Age', 'Gender', 'CH2O', 'FAF']\n",
      "Accuracy: 0.8114 (0.0266)\n"
     ]
    }
   ],
   "source": [
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "outer_results = list()\n",
    "\n",
    "selected_feature_names = []\n",
    "\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "    cv_inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    model = RandomForestClassifier()\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 1000],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'max_depth': [10, 50],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 4],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "    }\n",
    "    search = GridSearchCV(model, param_grid, scoring='accuracy', cv=cv_inner, refit=True)\n",
    "    result = search.fit(X_train, y_train)\n",
    "    best_model = result.best_estimator_\n",
    "\n",
    "    feature_selector = SelectFromModel(best_model, threshold='median')\n",
    "    feature_selector.fit(X_train, y_train)\n",
    "    X_train_selected = feature_selector.transform(X_train)\n",
    "    X_test_selected = feature_selector.transform(X_test)\n",
    "\n",
    "    selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "    selected_features = [features[i] for i in selected_feature_indices if i < len(features)]\n",
    "    selected_feature_names.append(selected_features)\n",
    "\n",
    "    best_model.fit(X_train_selected, y_train)\n",
    "    yhat = best_model.predict(X_test_selected)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    outer_results.append(acc)\n",
    "    print('> accuracy = %f, Best_params = %s' % (acc, result.best_params_))\n",
    "\n",
    "for fold, features in enumerate(selected_feature_names):\n",
    "    print(f'Fold {fold+1} - Selected Features: {features}')\n",
    "\n",
    "print('Accuracy: %.4f (%.4f)' % (mean(outer_results), std(outer_results)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbcddb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
